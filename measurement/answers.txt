Q2: Predicted latency: 0.117ms  Predicted throughput: 1691.2604 Mbps
    Average RTT: 161.026ms      Measured throughput: 23.0512 Mbps

    We had a really high round trip time and really low throughput. This could be caused by a number of things, including a bad connection between (one of) the hosts and the switch. Our prediction was wrong because we never measured the latency and throughput between the switches and the hosts. We only measured the latency and throughput between switches. In this case, the latency between h1 - s1 and/or h4 - s4 were high and the throughput low, which significantly impacted our results. 

Q3: The latency should stay about the same (~160ms) but the throughput will half (with two pairs) or 1/3 (with three pairs). 
    Average RTT h4 - h1: 160.700ms      Average RTT h4 - h8: 161.053ms
    Throughput h4 - h1: 7.5628 Mbps    Throughput h4 - h8: 18.1508 Mbps
    This is about what we predicted. The average round trip time stayed about the same as Q2 because it's still basically the same path in the network. However, we were incorrect about the throughput. It seems as if one pair takes about two-thirds of the throughput and then the other only gets a third. This could be due to a variety of factors such as QOS or the link between the host and the switch itself is throttled/bottlenecked.

    Average RTT h4-h1: 161.558ms    Average RTT h4-h7: 162.012ms    Average RTT h4-h8: 161.592ms
    Throughput h4-h1: 12.0944 Mbps  Throughput h4-h7: 7.14 Mbps     Throughput h4-h8: 7.3148 Mbps
    Here, again we confirm that the RTT is basically the same. We also see here again that one pair takes up most of the throughput, this time about half, and then the other two pairs split the remaining half of the throughput. Again, this could be due to QOS or degraded link between the host and switch. 

Q4: Our predicted latency for each pair is 160ms and predicted throughput is ~12 Mbps, or about the average of the two pair in question 3. We know, roughly, the latency and throughput for h1 to h4 when there is two pairs communicating so we are predicting h5 to h6 to have about the same latency and throughput. However, we don't know the connection latency and throughput of h5 to s5 and h6 to s6, so either one of those could cause a bottleneck here.
    Average RTT h1-h4: 161.030ms    Average RTT h5-h6: 40.816ms
    Throughput h1-h4: 18.5572 Mbps  Throughput h5-h6: 24.4648 Mbps

    As expected, the latency for h1 to h4 was around 160ms. However, it had a higher throughput than predicted. h5 to h6 also had a lower latency and higher throughput than predicted. This suggests that our bottleneck was switch 1 in question 3 because the path between switch 2, 3, and 4 had the higher throughput even when switch 2 and 3 were loaded with two pairs. Our prediction for h5-h6 was also wrong because even though we knew the latency and throughput for switches 5, 2, 3, and 6, and links 4, 2, and 5, we don't know the latency and throughput for the link between host 5 and switch 5 and host 6 and switch 6. The lower latency and higher throughput for h5-h6 also suggests that the second bottleneck in the path between h1 and h4 is switch 4 because both pairs share switches 2 and 3 and h5-h6 had a significantly lower RTT than h1-h4.